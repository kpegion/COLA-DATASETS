{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re \n",
    "os.chdir(\"C://Users//Noushin//Desktop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = open('final_monthly.txt', 'w')\n",
    "with open(\"mon_6th_res_edited.txt\") as fp:\n",
    "    lines = fp.readlines()\n",
    "    tags = 'gridded,global,model,monthly'\n",
    "    for line in lines:\n",
    "        _path , _file = os.path.split(line)\n",
    "        _name = re.match('.*_',_file)\n",
    "        try:\n",
    "            _name = _name.group(0)\n",
    "            dataset_name = _name[:-1]\n",
    "            gen_name = _name+'*.nc'\n",
    "            gen_full = _path + \"/\" + gen_name\n",
    "            outp.write('\"'+gen_full+ '\"'+ '\\t'+ dataset_name + '\\t' + tags+  '\\n')\n",
    "        except:\n",
    "            print(line)\n",
    "outp.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = open('fake_monthly.txt', 'w')\n",
    "with open(\"mon_6th_res_edited.txt\") as fp:\n",
    "    lines = fp.readlines()\n",
    "    tags = 'gridded,global,model,monthly'\n",
    "    for line in lines:\n",
    "        _path , _file = os.path.split(line)\n",
    "        _name = re.match('.*_',_file)\n",
    "        try:\n",
    "            _name = _name.group(0)\n",
    "            dataset_name = _name.replace('_','')\n",
    "            gen_name = _name+'*.nc'\n",
    "            gen_full = _path + \"/\" + gen_name\n",
    "            outp.write(gen_full+'\\n')\n",
    "        except:\n",
    "            print(line)\n",
    "outp.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = open('final_daily.txt', 'w') \n",
    "with open(\"day_6th_res.txt\") as fp:\n",
    "    lines = fp.readlines()\n",
    "    tags = 'gridded,global,model,daily'\n",
    "    for line in lines:\n",
    "        line = line.replace('/day/day/','/day/')\n",
    "        _path , _file = os.path.split(line)\n",
    "        _name = re.match('.*_',_file)\n",
    "        try:\n",
    "            _name = _name.group(0)\n",
    "            dataset_name = _name[:-1]\n",
    "            gen_name = _name+'*.nc'\n",
    "            gen_full = _path + \"/\" + gen_name\n",
    "            outp.write('\"'+gen_full+ '\"' + '\\t'+ dataset_name + '\\t' + tags+  '\\n')\n",
    "        except:\n",
    "            print(line)\n",
    "outp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = open('fake_daily.txt', 'w')\n",
    "with open(\"day_6th_res.txt\") as fp:\n",
    "    lines = fp.readlines()\n",
    "    tags = 'gridded,global,model,daily'\n",
    "    for line in lines:\n",
    "        _path , _file = os.path.split(line)\n",
    "        _name = re.match('.*_',_file)\n",
    "        try:\n",
    "            _name = _name.group(0)\n",
    "            dataset_name = _name[:-1]\n",
    "            gen_name = _name+'*.nc'\n",
    "            gen_full = _path + \"/\" + gen_name\n",
    "            outp.write(gen_full+'\\n')\n",
    "        except:\n",
    "            print(line)\n",
    "outp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing \"\" for the ones with only one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('52_of_53_daily_failed.txt') as inp:\n",
    "    lines = inp.readlines()\n",
    "    small_set= set()\n",
    "    for line in lines:\n",
    "        small_set.add(line.strip())\n",
    "\n",
    "backup = []\n",
    "with open('final_daily.txt') as outp:\n",
    "    lines = outp.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        edited = line.split('\\t')\n",
    "        edited_path = edited[0].split('\"')[1]\n",
    "        if edited_path in small_set:\n",
    "            #print(edited_path)\n",
    "            new_ln = '\\t'.join((edited_path, edited[1],edited[2]))\n",
    "            backup.append(new_ln)\n",
    "        else:\n",
    "            backup.append(line)\n",
    "\n",
    "\n",
    "with open('new_final.txt', 'w') as fp:\n",
    "    fp.write(''.join(backup))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
